{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_files\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D\n",
    "from keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import gc\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#Data directories\n",
    "train_directory = '../input/fruits/fruits-360_dataset/fruits-360/Training'\n",
    "test_directory = '../input/fruits/fruits-360_dataset/fruits-360/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data:\n",
    "train_data = load_files(train_directory)\n",
    "test_data = load_files(test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train_data['filenames'][:32000])\n",
    "#convert file paths to image arrays:\n",
    "X_train_img_array = []\n",
    "for file in X_train:\n",
    "    X_train_img_array.append(img_to_array(load_img(file)))\n",
    "X_train = np.array(X_train_img_array)\n",
    "del X_train_img_array\n",
    "\n",
    "\n",
    "X_test = np.array(test_data['filenames'][:9000])\n",
    "#convert file paths to image arrays:\n",
    "X_test_img_array = []\n",
    "for file in X_test:\n",
    "    X_test_img_array.append(img_to_array(load_img(file)))\n",
    "X_test = np.array(X_test_img_array)\n",
    "del X_test_img_array\n",
    "\n",
    "\n",
    "y_train = np.array(train_data['target'][:32000])\n",
    "target_labels = np.array(train_data['target_names'])\n",
    "y_test = np.array(test_data['target'][:9000])\n",
    "\n",
    "num_labels = len(np.unique(y_train))\n",
    "\n",
    "del train_data\n",
    "del test_data\n",
    "\n",
    "#images are 255 intensity, so normalize:\n",
    "X_train = X_train/255\n",
    "X_test = X_test/255\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "print('Shape of training set: ', X_train.shape)\n",
    "print('Shape of test set: ', X_test.shape)\n",
    "print('Number of possible labels: ', num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's take a look at some of the images\n",
    "\n",
    "fig1 = plt.figure(figsize = (20,10))\n",
    "for i, idx in enumerate(np.random.choice(X_train.shape[0], size=18, replace=False)):\n",
    "    subplt = fig1.add_subplot(3,6,i+1)\n",
    "    subplt.imshow(X_train[idx])\n",
    "    label_index = y_train[idx]\n",
    "    subplt.set_title(target_labels[label_index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at target\n",
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to one-hot encode the target so it works with the CNN final output softmax:\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, num_labels)\n",
    "y_test = np_utils.to_categorical(y_test, num_labels)\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN model building time:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 16, kernel_size = 4, padding = 'same', activation = 'relu', input_shape = (100,100,3)))\n",
    "model.add(Conv2D(filters = 32, kernel_size = 4, padding = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = 4, padding ='same', activation = 'relu'))\n",
    "model.add(Conv2D(filters = 64, kernel_size = 4, padding ='same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = 2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# model.add(Conv2D(filters = 128, kernel_size = 4, padding ='same', activation = 'relu'))\n",
    "# model.add(MaxPooling2D(pool_size = 2))\n",
    "# model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(num_labels, activation = 'softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate = 0.001, beta_1 = 0.9, beta_2 = 0.999, amsgrad=False)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and validation sets. With size of our data set, we can do ~20% validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state = 0, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the model\n",
    "\n",
    "history = model.fit(X_train,y_train,\n",
    "        batch_size = 64,\n",
    "        epochs=20,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate accurate on test set\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test % accuracy:', score[1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at predictions for test images:\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "fig2 = plt.figure(figsize=(20, 10))\n",
    "for i, idx in enumerate(np.random.choice(X_test.shape[0], size=18, replace=False)):\n",
    "    subplt = fig2.add_subplot(3, 6, i + 1)\n",
    "    subplt.imshow(X_test[idx])\n",
    "    pred_index = np.argmax(y_pred[idx])\n",
    "    true_index = np.argmax(y_test[idx])\n",
    "    subplt.set_title(f\"Actual: {target_labels[true_index]}\")\n",
    "    subplt.text(5, 10, f\"Predicted: {target_labels[pred_index]}\", color='k', backgroundcolor=(\"white\" if pred_index == true_index else \"red\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://keras.io/visualization/\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(2,1,1) \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.subplot(2,1,2) \n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at some examples of images we classified wrongly:\n",
    "\n",
    "wrong_indices =[]\n",
    "L = len(y_pred)\n",
    "for i in range(L):\n",
    "    if np.argmax(y_pred[i]) != np.argmax(y_test[i]):\n",
    "        wrong_indices.append(i)\n",
    "\n",
    "print(\"Size of test set: \", L)\n",
    "print(\"Total wrong: \", len(wrong_indices))\n",
    "print(\"% Wrong:\", 100*len(wrong_indices)/L)\n",
    "        \n",
    "fig3 = plt.figure(figsize=(20, 10))\n",
    "for i, idx in enumerate(np.random.choice(wrong_indices, size=18, replace=False)):\n",
    "    subplt = fig3.add_subplot(3, 6, i + 1)\n",
    "    subplt.imshow(X_test[idx])\n",
    "    pred_index = np.argmax(y_pred[idx])\n",
    "    true_index = np.argmax(y_test[idx])\n",
    "    subplt.set_title(f\"Actual: {target_labels[true_index]}\")\n",
    "    subplt.text(5, 10, f\"Predicted: {target_labels[pred_index]}\", color='k', backgroundcolor=\"red\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it is hard to classify bananas from the perspective that does not show their curvature, and round red foods, like apple/tomato/nectarine/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
